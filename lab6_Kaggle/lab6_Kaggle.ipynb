{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from tensorflow.python.framework.ops import reset_default_graph\n",
    "\n",
    "def onehot(t, num_classes):\n",
    "    out = np.zeros((t.shape[0], num_classes))\n",
    "    for row, col in enumerate(t):\n",
    "        out[row, col] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle challenge\n",
    "\n",
    "In this lab we will work on a data science challenge from `kaggle.com`.\n",
    "Kaggle is a website to participate in real life challenges.\n",
    "Most competitions on kaggle have a dataset, an accuracy metric and a leaderboard to compare submissions.\n",
    "You can read more about kaggle [here](https://www.kaggle.com/about).\n",
    "\n",
    "OBS: You will need a kaggle account for this exercise!\n",
    "\n",
    "The challenge we will pursue is the [_Leaf Classification_](https://www.kaggle.com/c/leaf-classification) challenge.\n",
    "The dataset consists approximately 1,584 images of leaf specimens (16 samples each of 99 species) which have been converted to binary black leaves against white backgrounds. Three sets of features are also provided per image: a shape contiguous descriptor, an interior texture histogram, and a ï¬ne-scale margin histogram. For each feature, a 64-attribute vector is given per leaf sample.\n",
    "\n",
    "The first task in a kaggle competition is to download, understand and preprocess the data. This we will do in the first section.\n",
    "\n",
    "Afterwards, we will look into the type of neural network best suited for handling this type of data. For images, usually the convolutional neural network does a pretty good job, for timeseries (like the shape) usually the RNN is the network of choice.\n",
    "\n",
    "Lastly, we will train the model and put the outputs in a submission file that we can submit to kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data\n",
    "\n",
    "Go to the [data section](https://www.kaggle.com/c/leaf-classification/data) of the Leaf Classification competition on kaggle.\n",
    "\n",
    "Next, download all of the available data (`sample_submission.csv`, `train.csv`, `test.csv`, `images`), accept the disclaimer if asked and unzip all folders into the `lab6` folder.\n",
    "Such that\n",
    "\n",
    "```\n",
    ">ls $PATH\\_TO\\_FOLDER/tensorflow_tutorial/lab6\n",
    "images  lab6_Kaggle.ipynb  README.md  sample_submission.csv  test.csv  train.csv\n",
    "```\n",
    "\n",
    "Below we will try to load the data into memory and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_paths = glob.glob(\"images/*\")\n",
    "print \"Amount of images =\", len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now plot 10 images\n",
    "# as we need all images to have the same dimensionality, we will resize and plot\n",
    "# make the images as small as possible, until the difference between starts to get blurry\n",
    "for i in range(10):\n",
    "    image = imread(image_paths[i], as_grey=True)\n",
    "    #image = resize(image, output_shape=(100, 100))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(\"name: %s \\n shape:%s\" % (image_paths[i], image.shape))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now loading the train.csv to find features for each training point\n",
    "train = pd.read_csv('train.csv')\n",
    "# notice how we \"only\" have 990 (989+0 elem) images for training, the rest is for testing\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now do similar as in train example above for test.csv\n",
    "test = pd.read_csv('test.csv')\n",
    "# notice that we do not have species here, we need to predict that ..!\n",
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# and now do similar as in train example above for test.csv\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "# accordingly to these IDs we need to provide the probability of a given plant being present\n",
    "sample_submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# name all columns in train, should be 3 different columns with 64 values each\n",
    "print train.columns[2::64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try and extract and plot columns\n",
    "X = train.as_matrix(columns=train.columns[2:])\n",
    "print \"X.shape,\", X.shape\n",
    "margin = X[:, :64]\n",
    "shape = X[:, 64:128]\n",
    "texture = X[:, 128:]\n",
    "print \"margin.shape,\", margin.shape\n",
    "print \"shape.shape,\", shape.shape\n",
    "print \"texture.shape,\", texture.shape\n",
    "# let us plot some of the features\n",
    "plt.figure(figsize=(21,7))\n",
    "for i in range(3):\n",
    "    plt.subplot(3,3,1+i*3)\n",
    "    plt.plot(margin[i])\n",
    "    if i == 0:\n",
    "        plt.title('Margin', fontsize=20)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(3,3,2+i*3)\n",
    "    plt.plot(shape[i])\n",
    "    if i == 0:\n",
    "        plt.title('Shape', fontsize=20)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(3,3,3+i*3)\n",
    "    plt.plot(texture[i])\n",
    "    if i == 0:\n",
    "        plt.title('Texture', fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "1. Test various resizings of the image until you have found the smallest resizing of the image where you can still see differentiate between the images.\n",
    "\n",
    "2. From the illustration of the Margin, Shape and Texture, what do you see? And how can it be used to classify?\n",
    "\n",
    "3. Describe what network you would build and how you would represent the data points (image, margin, shape and texture)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Building data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from tensorflow.python.framework.ops import reset_default_graph\n",
    "import os\n",
    "import subprocess\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "\n",
    "def onehot(t, num_classes):\n",
    "    out = np.zeros((t.shape[0], num_classes))\n",
    "    for row, col in enumerate(t):\n",
    "        out[row, col] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class load_data():\n",
    "    # data_train, data_test and le are public\n",
    "    def __init__(self, train_path, test_path, image_paths, image_shape=(128, 128)):\n",
    "        train_df = pd.read_csv(train_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "        image_paths = image_paths\n",
    "        image_shape = image_shape\n",
    "        self._load(train_df, test_df, image_paths, image_shape)\n",
    "        \n",
    "    def _load(self, train_df, test_df, image_paths, image_shape):\n",
    "        print \"loading data ...\"\n",
    "        # load train.csv\n",
    "        path_dict = self._path_to_dict(image_paths) # numerate image paths and make it a dict\n",
    "        # merge image paths with data frame\n",
    "        train_image_df = self._merge_image_df(train_df, path_dict)\n",
    "        test_image_df = self._merge_image_df(test_df, path_dict)\n",
    "        # label encoder-decoder (self. because we need it later)\n",
    "        self.le = LabelEncoder().fit(train_image_df['species'])\n",
    "        # labels for train\n",
    "        t_train = self.le.transform(train_image_df['species'])\n",
    "        # getting data\n",
    "        train_data = self._make_dataset(train_image_df, image_shape, t_train)\n",
    "        test_data = self._make_dataset(test_image_df, image_shape)        \n",
    "        # need to reformat the train for validation split reasons in the batch_generator\n",
    "        self.train = self._format_dataset(train_data, for_train=True)\n",
    "        self.test = self._format_dataset(test_data, for_train=False)\n",
    "        print \"data loaded\"\n",
    "        \n",
    "\n",
    "    def _path_to_dict(self, image_paths):\n",
    "        path_dict = dict()\n",
    "        for image_path in image_paths:\n",
    "            num_path = int(os.path.basename(image_path[:-4]))\n",
    "            path_dict[num_path] = image_path\n",
    "        return path_dict\n",
    "\n",
    "    def _merge_image_df(self, df, path_dict):\n",
    "        split_path_dict = dict()\n",
    "        for index, row in df.iterrows():\n",
    "            split_path_dict[row['id']] = path_dict[row['id']]\n",
    "        image_frame = pd.DataFrame(split_path_dict.values(), columns=['image'])\n",
    "        df_image =  pd.concat([image_frame, df], axis=1)\n",
    "        return df_image\n",
    "    \n",
    "\n",
    "    def _make_dataset(self, df, image_shape, t_train=None):\n",
    "        if t_train is not None:\n",
    "            print \"loading train ...\"\n",
    "        else:\n",
    "            print \"loading test ...\"\n",
    "        # make dataset\n",
    "        data = dict()\n",
    "        # merge image with 3x64 features\n",
    "        for i, dat in enumerate(df.iterrows()):\n",
    "            index, row = dat\n",
    "            sample = dict()\n",
    "            if t_train is not None:\n",
    "                features = row.drop(['id', 'species', 'image'], axis=0).values\n",
    "            else:\n",
    "                features = row.drop(['id', 'image'], axis=0).values\n",
    "            sample['margin'] = features[:64]\n",
    "            sample['shape'] = features[64:128]\n",
    "            sample['texture'] = features[128:]\n",
    "            if t_train is not None:\n",
    "                sample['t'] = np.asarray(t_train[i], dtype='int32')\n",
    "            image = imread(row['image'], as_grey=True)\n",
    "            image = resize(image, output_shape=image_shape)\n",
    "            image = np.expand_dims(image, axis=2)\n",
    "            sample['image'] = image   \n",
    "            data[row['id']] = sample\n",
    "            if i % 100 == 0:\n",
    "                print \"\\t%d of %d\" % (i, len(df))\n",
    "        return data\n",
    "\n",
    "    def _format_dataset(self, df, for_train):\n",
    "        # making arrays with all data in, is nessesary when doing validation split\n",
    "        data = dict()\n",
    "        value = df.values()[0]\n",
    "        img_tot_shp = tuple([len(df)] + list(value['image'].shape))\n",
    "        data['images'] = np.zeros(img_tot_shp, dtype='float32')\n",
    "        feature_tot_shp = (len(df), 64)\n",
    "        data['margins'] = np.zeros(feature_tot_shp, dtype='float32')\n",
    "        data['shapes'] = np.zeros(feature_tot_shp, dtype='float32')\n",
    "        data['textures'] = np.zeros(feature_tot_shp, dtype='float32')\n",
    "        if for_train:\n",
    "            data['ts'] = np.zeros((len(df),), dtype='int32')\n",
    "        else:\n",
    "            data['ids'] = np.zeros((len(df),), dtype='int32')\n",
    "        for i, pair in enumerate(df.items()):\n",
    "            key, value = pair\n",
    "            data['images'][i] = value['image']\n",
    "            data['margins'][i] = value['margin']\n",
    "            data['shapes'][i] = value['shape']\n",
    "            data['textures'][i] = value['texture']\n",
    "            if for_train:\n",
    "                data['ts'][i] = value['t']\n",
    "            else:\n",
    "                data['ids'][i] = key\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loading data and setting up constants\n",
    "TRAIN_PATH = \"train.csv\"\n",
    "TEST_PATH = \"test.csv\"\n",
    "IMAGE_PATHS = glob.glob(\"images/*.jpg\")\n",
    "NUM_CLASSES = 99\n",
    "IMAGE_SHAPE = (128, 128, 1)\n",
    "NUM_FEATURES = 64 # for all three features, margin, shape and texture\n",
    "# train holds both X (input) and t (target/truth)\n",
    "data = load_data(train_path=TRAIN_PATH, test_path=TEST_PATH,\n",
    "                 image_paths=IMAGE_PATHS, image_shape=IMAGE_SHAPE[:2])\n",
    "# to visualize the size of the dimensions of the data\n",
    "print\n",
    "print \"@@@Shape checking of data sets@@@\"\n",
    "print\n",
    "print \"TRAIN\"\n",
    "print \"\\timages\\t%s%f\" % (data.train['images'].shape, data.train['images'].mean())\n",
    "print \"\\tmargins\\t%s\\t%f\" % (data.train['margins'].shape, data.train['margins'].mean())\n",
    "print \"\\tshapes\\t%s\\t%f\" % (data.train['shapes'].shape, data.train['shapes'].mean())\n",
    "print \"\\ttextures%s\\t%f\" % (data.train['textures'].shape, data.train['textures'].mean())\n",
    "print \"\\tts\\t %s\" % (data.train['ts'].shape)\n",
    "print \"\\twhile training, batch_generator will onehot encode ts to (batch_size, num_classes)\"\n",
    "print\n",
    "print \"TEST\"\n",
    "print \"\\timages\\t%s\\t%f\" % (data.test['images'].shape, data.test['images'].mean()) \n",
    "print \"\\tmargins\\t%s\\t%f\" % (data.test['margins'].shape, data.test['margins'].mean())\n",
    "print \"\\tshapes\\t%s\\t%f\" % (data.test['shapes'].shape, data.test['shapes'].mean())\n",
    "print \"\\ttextures%s\\t%f\" % (data.test['textures'].shape, data.test['textures'].mean())\n",
    "print \"\\tids\\t%s\" % (data.test['ids'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batch generator\n",
    "\n",
    "While training, we will not directly access the entire dataset, instead we have a `batch_generator` function to give us inputs aligned with their targets/ids in a size that our model can handle in memory (batch\\_size).\n",
    "\n",
    "Furthermore, the `batch_generator` also handles validation splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class batch_generator():\n",
    "    def __init__(self, data, batch_size=64, num_classes=99,\n",
    "                 num_iterations=5e3, num_features=64, seed=42, val_size=0.1):\n",
    "        print \"initiating batch generator\"\n",
    "        self._train = data.train\n",
    "        self._test = data.test\n",
    "        # get image size\n",
    "        value = self._train['images'][0]\n",
    "        self._image_shape = list(value.shape)\n",
    "        self._batch_size = batch_size\n",
    "        self._num_classes = num_classes\n",
    "        self._num_iterations = num_iterations\n",
    "        self._num_features = num_features\n",
    "        self._seed = seed\n",
    "        self._val_size = 0.1\n",
    "        self._valid_split()\n",
    "        print \"batch generator initiated ...\"\n",
    "\n",
    "    def _valid_split(self):\n",
    "        self._idcs_train, self._idcs_valid = iter(\n",
    "            StratifiedShuffleSplit(self._train['ts'],\n",
    "                                   n_iter=1,\n",
    "                                   test_size=self._val_size,\n",
    "                                   random_state=self._seed)).next()\n",
    "    def _shuffle_train(self):\n",
    "        np.random.shuffle(self._idcs_train)\n",
    "\n",
    "    def _batch_init(self, purpose):\n",
    "        assert purpose in ['train', 'valid', 'test']\n",
    "        batch_holder = dict()\n",
    "        batch_holder['margins'] = np.zeros((self._batch_size, self._num_features), dtype='float32')\n",
    "        batch_holder['shapes'] = np.zeros((self._batch_size, self._num_features), dtype='float32')\n",
    "        batch_holder['textures'] = np.zeros((self._batch_size, self._num_features), dtype='float32')\n",
    "        batch_holder['images'] = np.zeros(tuple([self._batch_size] + self._image_shape), dtype='float32')\n",
    "        if (purpose == \"train\") or (purpose == \"valid\"):\n",
    "            batch_holder['ts'] = np.zeros((self._batch_size, self._num_classes), dtype='float32')          \n",
    "        else:\n",
    "            batch_holder['ids'] = []\n",
    "        return batch_holder\n",
    "\n",
    "    def gen_valid(self):\n",
    "        batch = self._batch_init(purpose='train')\n",
    "        i = 0\n",
    "        for idx in self._idcs_valid:\n",
    "            batch['margins'][i] = self._train['margins'][idx]\n",
    "            batch['shapes'][i] = self._train['shapes'][idx]\n",
    "            batch['textures'][i] = self._train['textures'][idx]\n",
    "            batch['images'][i] = self._train['images'][idx]\n",
    "            batch['ts'][i] = onehot(np.asarray([self._train['ts'][idx]], dtype='float32'), self._num_classes)\n",
    "            i += 1\n",
    "            if i >= self._batch_size:\n",
    "                yield batch, i\n",
    "                batch = self._batch_init(purpose='valid')\n",
    "                i = 0\n",
    "        if i != 0:\n",
    "            yield batch, i\n",
    "\n",
    "    def gen_test(self):\n",
    "        batch = self._batch_init(purpose='test')\n",
    "        i = 0\n",
    "        for idx in range(len(self._test['ids'])):\n",
    "            batch['margins'][i] = self._test['margins'][idx]\n",
    "            batch['shapes'][i] = self._test['shapes'][idx]\n",
    "            batch['textures'][i] = self._test['textures'][idx]\n",
    "            batch['images'][i] = self._test['images'][idx]\n",
    "            batch['ids'].append(self._test['ids'][idx])\n",
    "            i += 1\n",
    "            if i >= self._batch_size:\n",
    "                yield batch, i\n",
    "                batch = self._batch_init(purpose='test')\n",
    "                i = 0\n",
    "        if i != 0:\n",
    "            yield batch, i\n",
    "            \n",
    "\n",
    "    def gen_train(self):\n",
    "        batch = self._batch_init(purpose='train')\n",
    "        iteration = 0\n",
    "        i = 0\n",
    "        while True:\n",
    "            # shuffling all batches\n",
    "            self._shuffle_train()\n",
    "            for idx in self._idcs_train:\n",
    "                # extract data from dict\n",
    "                batch['margins'][i] = self._train['margins'][idx]\n",
    "                batch['shapes'][i] = self._train['shapes'][idx]\n",
    "                batch['textures'][i] = self._train['textures'][idx]\n",
    "                batch['images'][i] = self._train['images'][idx]\n",
    "                batch['ts'][i] = onehot(np.asarray([self._train['ts'][idx]], dtype='float32'), self._num_classes)\n",
    "                i += 1\n",
    "                if i >= self._batch_size:\n",
    "                    yield batch\n",
    "                    batch = self._batch_init(purpose='train')\n",
    "                    i = 0\n",
    "                    iteration += 1\n",
    "                    if iteration >= self._num_iterations:\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummy_batch_gen = batch_generator(data, batch_size=64, num_classes=99, num_iterations=5e3, seed=42)\n",
    "train_batch = dummy_batch_gen.gen_train().next()\n",
    "valid_batch, i = dummy_batch_gen.gen_valid().next()\n",
    "test_batch, i = dummy_batch_gen.gen_test().next()\n",
    "\n",
    "print\n",
    "print \"@@@Shape/mean checking of batches@@@\"\n",
    "print\n",
    "print \"TRAIN\"\n",
    "print \"\\timages,\", train_batch['images'].shape\n",
    "print \"\\tmargins,\", train_batch['margins'].shape\n",
    "print \"\\tshapes,\", train_batch['shapes'].shape\n",
    "print \"\\ttextures,\", train_batch['textures'].shape\n",
    "print \"\\tts,\", train_batch['ts'].shape\n",
    "print\n",
    "print \"VALID\"\n",
    "print \"\\timages,\", valid_batch['images'].shape\n",
    "print \"\\tmargins,\", valid_batch['margins'].shape\n",
    "print \"\\tshapes,\", valid_batch['shapes'].shape\n",
    "print \"\\ttextures,\", valid_batch['textures'].shape\n",
    "print \"\\tts,\", valid_batch['ts'].shape\n",
    "print\n",
    "print \"TEST\"\n",
    "print \"\\timages,\", test_batch['images'].shape\n",
    "print \"\\tmargins,\", test_batch['margins'].shape\n",
    "print \"\\tshapes,\", test_batch['shapes'].shape\n",
    "print \"\\ttextures,\", test_batch['textures'].shape\n",
    "print \"\\tids,\", len(test_batch['ids'])\n",
    "# notice that mean is very different, which is why we use batch_norm in all input data in model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation on contrib layers\n",
    "Check out the [github page](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py) for information on contrib layers (not well documented in their api)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected, convolution2d, flatten, batch_norm, max_pool2d, dropout\n",
    "from tensorflow.python.ops.nn import relu, elu, relu6, sigmoid, tanh, softmax\n",
    "from tensorflow.python.ops.nn import dynamic_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_pre(l_in, num_outputs, kernel_size, scope, stride=1):\n",
    "    return convolution2d(l_relu, num_outputs=num_outputs, kernel_size=kernel_size,\n",
    "                         stride=stride, normalize_fn=batch_norm, scope=scope)\n",
    "\n",
    "# pre-activation: http://arxiv.org/abs/1603.05027\n",
    "# wrapping convolutions and batch_norm\n",
    "def conv_pre(l_in, num_outputs, kernel_size, scope, stride=1):\n",
    "    l_norm = batch_norm(l_in)\n",
    "    l_relu = relu(l_norm)\n",
    "    return convolution2d(l_relu, num_outputs=num_outputs, kernel_size=kernel_size,\n",
    "                         stride=stride, activation_fn=None, scope=scope)\n",
    "# easy to use pool function\n",
    "def pool(l_in, scope, kernel_size=(3, 3)):\n",
    "    return max_pool2d(l_in, kernel_size=kernel_size, scope=scope) # (3, 3) has shown to work better than (2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hyperameters of the model\n",
    "height, width, channels = IMAGE_SHAPE\n",
    "# resetting the graph ...\n",
    "reset_default_graph()\n",
    "\n",
    "# Setting up placeholder, this is where your data enters the graph!\n",
    "x_image_pl = tf.placeholder(tf.float32, [None, height, width, channels], name=\"x_image_pl\")\n",
    "x_margin_pl = tf.placeholder(tf.float32, [None, NUM_FEATURES], name=\"x_margin_pl\")\n",
    "x_shape_pl = tf.placeholder(tf.float32, [None, NUM_FEATURES], name=\"x_shape_pl\")\n",
    "x_texture_pl = tf.placeholder(tf.float32, [None, NUM_FEATURES], name=\"x_texture_pl\")\n",
    "is_training_pl = tf.placeholder(tf.bool, name=\"is_training_pl\")\n",
    "\n",
    "# Building the layers of the neural network\n",
    "# we define the variable scope, so we more easily can recognise our variables later\n",
    "\n",
    "## IMAGE\n",
    "#l_conv1_a = conv(x_image_pl, 16, (5, 5), scope=\"l_conv1_a\")\n",
    "#l_pool1 = pool(l_conv1_a, scope=\"l_pool1\")\n",
    "#l_conv2_a = conv(l_pool1, 16, (5, 5), scope=\"l_conv2_a\")\n",
    "#l_pool2 = pool(l_conv2_a, scope=\"l_pool2\")\n",
    "#l_conv3_a = conv(l_pool2, 16, (5, 5), scope=\"l_conv3_a\")\n",
    "#l_pool3 = pool(l_conv3_a, scope=\"l_pool3\")\n",
    "#l_conv4_a = conv(l_pool3, 16, (5, 5), scope=\"l_conv4_a\")\n",
    "#l_pool4 = pool(l_conv3_a, scope=\"l_pool4\")\n",
    "#l_flatten = flatten(l_pool4, scope=\"flatten\")\n",
    "\n",
    "## FEATURES\n",
    "# RNNs\n",
    "#shape_cell = tf.nn.rnn_cell.GRUCell(100)\n",
    "#_, shape_state = tf.nn.dynamic_rnn(cell=shape_cell,\n",
    "#    inputs=tf.expand_dims(batch_norm(x_shape_pl), 2), dtype=tf.float32, scope=\"shape_rnn\")\n",
    "\n",
    "## COMBINE\n",
    "features = tf.concat(concat_dim=1, values=[x_margin_pl, x_shape_pl, x_texture_pl], name=\"features\")\n",
    "#features = l_flatten\n",
    "#features = tf.concat(concat_dim=1, values=[x_margin_pl, shape_state, x_texture_pl], name=\"features\")\n",
    "features = batch_norm(features, scope='features_bn')\n",
    "#l2 = fully_connected(features, num_outputs=256, activation_fn=relu,\n",
    "#                     normalizer_fn=batch_norm, scope=\"l2\")\n",
    "#l2 = dropout(l2, is_training=is_training_pl, scope=\"l2_dropout\")\n",
    "y = fully_connected(features, NUM_CLASSES, activation_fn=softmax, scope=\"y\")\n",
    "\n",
    "# add TensorBoard summaries for all variables\n",
    "tf.contrib.layers.summarize_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PRINT NETWORK\n",
    "\n",
    "print \"x_image_pl,\", x_image_pl.get_shape\n",
    "print \"x_margin_pl,\", x_margin_pl.get_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clip_norm = 1\n",
    "# y_ is a placeholder variable taking on the value of the target batch.\n",
    "ts_pl = tf.placeholder(tf.float32, [None, NUM_CLASSES], name=\"targets_pl\")\n",
    "lr_pl = tf.placeholder(tf.float32, [], name=\"learning_rate_pl\")\n",
    "\n",
    "def loss_and_acc(preds):\n",
    "    # computing cross entropy per sample\n",
    "    cross_entropy = -tf.reduce_sum(ts_pl * tf.log(preds+1e-10), reduction_indices=[1])\n",
    "    # averaging over samples\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "    # if you want regularization\n",
    "    #reg_scale = 0.0001\n",
    "    #regularize = tf.contrib.layers.l2_regularizer(reg_scale)\n",
    "    #params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "    #reg_term = sum([regularize(param) for param in params])\n",
    "    #loss += reg_term\n",
    "    # calculate accuracy\n",
    "    argmax_y = tf.to_int32(tf.argmax(preds, dimension=1))\n",
    "    argmax_t = tf.to_int32(tf.argmax(ts_pl, dimension=1))\n",
    "    correct = tf.to_float(tf.equal(argmax_y, argmax_t))\n",
    "    accuracy = tf.reduce_mean(correct)\n",
    "    return loss, accuracy, argmax_y\n",
    "\n",
    "# loss, accuracy and prediction\n",
    "loss, accuracy, prediction = loss_and_acc(y)\n",
    "valid_loss = loss\n",
    "valid_accuracy = accuracy\n",
    "\n",
    "# defining our optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "\n",
    "# applying the gradients\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "gradients, variables = zip(*grads_and_vars)  # unzip list of tuples\n",
    "clipped_gradients, global_norm = (\n",
    "    tf.clip_by_global_norm(gradients, clip_norm) )\n",
    "clipped_grads_and_vars = zip(clipped_gradients, variables)\n",
    "\n",
    "# make training op for applying the gradients\n",
    "train_op = optimizer.apply_gradients(clipped_grads_and_vars)\n",
    "\n",
    "# make tensorboard summeries\n",
    "tf.scalar_summary('train/global gradient norm', global_norm)\n",
    "tf.scalar_summary('train/loss', loss)\n",
    "tf.scalar_summary('train/accuracy', accuracy)\n",
    "tf.scalar_summary('validation/loss', valid_loss)\n",
    "tf.scalar_summary('validation/accuracy', valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test the forward pass\n",
    "_img_shape = tuple([45]+list(IMAGE_SHAPE))\n",
    "_feature_shape = (45, NUM_FEATURES)\n",
    "_x_image = np.random.normal(0, 1, _img_shape).astype('float32') #dummy data\n",
    "_x_margin = np.random.normal(0, 1, _feature_shape).astype('float32')\n",
    "_x_shape = np.random.normal(0, 1, _feature_shape).astype('float32')\n",
    "_x_texture = np.random.normal(0, 1, _feature_shape).astype('float32')\n",
    "\n",
    "# restricting memory usage, TensorFlow is greedy and will use all memory otherwise\n",
    "gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.2)\n",
    "# initialize the Session\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts))\n",
    "# test the forward pass\n",
    "sess.run(tf.initialize_all_variables())\n",
    "feed_dict = {x_image_pl: _x_image,\n",
    "             x_margin_pl: _x_margin,\n",
    "             x_shape_pl: _x_shape,\n",
    "             x_texture_pl: _x_texture,\n",
    "             is_training_pl: False}\n",
    "res_forward_pass = sess.run(fetches=[y], feed_dict=feed_dict)\n",
    "print \"y\", res_forward_pass[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Training Loop\n",
    "BATCH_SIZE = 64\n",
    "ITERATIONS = 1e4\n",
    "LOG_FREQ = 10\n",
    "VALIDATION_SIZE = 0.1 # 0.1 is ~ 100 samples for valition\n",
    "SEED = 42\n",
    "DROPOUT = True\n",
    "LEARNING_RATE = 0.0005\n",
    "VALID_EVERY = 100\n",
    "\n",
    "batch_gen = batch_generator(data, batch_size=BATCH_SIZE, num_classes=NUM_CLASSES,\n",
    "                            num_iterations=ITERATIONS, seed=SEED, val_size=VALIDATION_SIZE)\n",
    "\n",
    "# clean previous summaries\n",
    "#if os.path.isdir(\"tensorboard\"):\n",
    "#    bashCommand = \"rm -rf tensorboard\"\n",
    "#    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "#    output = process.communicate()[0]\n",
    "\n",
    "# write summaries\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "summaries_path = \"tensorboard/%s/logs\" % (timestamp)\n",
    "summaries = tf.merge_all_summaries()\n",
    "summarywriter = tf.train.SummaryWriter(summaries_path, sess.graph)\n",
    "\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "print \"\\ttrain_loss \\ttrain_acc \\tvalid_loss \\tvalid_acc\"\n",
    "for i, batch_train in enumerate(batch_gen.gen_train()):\n",
    "    if i>=ITERATIONS:\n",
    "        break\n",
    "    fetches_train = [train_op, loss, accuracy, summaries]\n",
    "    feed_dict_train = {\n",
    "        x_image_pl: batch_train['images'],\n",
    "        x_margin_pl: batch_train['margins'],\n",
    "        x_shape_pl: batch_train['shapes'],\n",
    "        x_texture_pl: batch_train['textures'],\n",
    "        ts_pl: batch_train['ts'],\n",
    "        is_training_pl: DROPOUT,\n",
    "        lr_pl: LEARNING_RATE,\n",
    "        \n",
    "    }\n",
    "    res_train = sess.run(fetches=fetches_train, feed_dict=feed_dict_train)\n",
    "    if i % LOG_FREQ == 0:\n",
    "        summarywriter.add_summary(res_train[3], i)\n",
    "    train_loss.append(res_train[1])\n",
    "    train_acc.append(res_train[2])\n",
    "    \n",
    "    if i % VALID_EVERY == 0:\n",
    "        cur_acc = 0\n",
    "        cur_loss = 0\n",
    "        tot_num = 0\n",
    "        for batch_valid, num in batch_gen.gen_valid():\n",
    "            fetches_valid = [loss, accuracy, summaries]\n",
    "            feed_dict_valid = {\n",
    "                x_image_pl: batch_valid['images'],\n",
    "                x_margin_pl: batch_valid['margins'],\n",
    "                x_shape_pl: batch_valid['shapes'],\n",
    "                x_texture_pl: batch_valid['textures'],\n",
    "                ts_pl: batch_valid['ts'],\n",
    "                is_training_pl: False,\n",
    "            }\n",
    "            res_valid = sess.run(fetches=fetches_valid, feed_dict=feed_dict_valid)\n",
    "            if LOG_FREQ % (i+1) == 0:\n",
    "                summarywriter.add_summary(res_valid[2], i)\n",
    "            cur_loss += res_valid[0]*num\n",
    "            cur_acc += res_valid[1]*num\n",
    "            tot_num += num\n",
    "        valid_loss = cur_loss / float(tot_num)\n",
    "        valid_acc = (cur_acc / float(tot_num)) * 100\n",
    "        train_loss = sum(train_loss) / float(len(train_loss))\n",
    "        train_acc = sum(train_acc) / float(len(train_acc)) * 100\n",
    "        print \"%d:\\t  %.2f\\t\\t  %.1f\\t\\t  %.2f\\t\\t  %.1f\" % (i, train_loss, train_acc, valid_loss, valid_acc)\n",
    "        train_loss = []\n",
    "        train_acc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard\n",
    "\n",
    "The code above has TensorBoard tracking histograms of all layers, train gradient norm, accuracy, loss, validation accuracy and loss.\n",
    "\n",
    "The TensorBoard summaries are written to the tensorboard folder. To enable TensorBoard start a new Docker instance forwarding port 6006, as below\n",
    "\n",
    "```\n",
    "> docker run -p 6006:6006 -v ~/misc:/mnt/myproject -it alrojo/tf-sklearn-cpu\n",
    "> cd mnt/myproject/tensorflow_tutorial/lab6_Kaggle\n",
    "> tensorboard --logdir=tensorboard\n",
    "```\n",
    "Now open a browser window and connect to `localhost:6006`, here you should find the TensorBoard of your current run.\n",
    "\n",
    "Note: CTRL+c when running TensorBoard might cause the program to halt. To terminate it just exit the terminal, open a new terminal, type\n",
    "\n",
    "```\n",
    "> docker ps\n",
    "```\n",
    "\n",
    "if your output looks something like this:\n",
    "```\n",
    "CONTAINER ID        IMAGE                   COMMAND             CREATED             STATUS              PORTS                              NAMES\n",
    "e62ed10401cd        alrojo/tf-sklearn-cpu   \"/bin/bash\"         16 minutes ago      Up 16 minutes       0.0.0.0:6006->6006/tcp, 8888/tcp   gigantic_euler\n",
    "7846236dbf57        alrojo/tf-sklearn-cpu   \"/bin/bash\"         About an hour ago   Up About an hour    6006/tcp, 0.0.0.0:8888->8888/tcp   high_gates\n",
    "\n",
    "```\n",
    "\n",
    "That means you still have the docker running and you need to shut it down if you want to run a new docker with the same port forwarding. To do, use either the `CONTAINER ID` or the `NAMES` and run:\n",
    "\n",
    "```\n",
    "> docker kill gigantic_euler\n",
    "```\n",
    "Note: In my case the `NAMES` was `gigantic_euler`, yours might be different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission to Kaggle\n",
    "\n",
    "First we have to make testset predictions, then we have to place it in the submission file and the upload to kaggle for our score! You can upload at max 5 submissions a day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GET PREDICTIONS\n",
    "# containers to collect ids and predictions\n",
    "ids_test = []\n",
    "preds_test = []\n",
    "# run like with validation\n",
    "for batch_test, num in batch_gen.gen_test():\n",
    "    # fetching for test we only need y\n",
    "    fetches_test = [y]\n",
    "    # same as validation, but no batch['ts']\n",
    "    feed_dict_test = {\n",
    "        x_image_pl: batch_test['images'],\n",
    "        x_margin_pl: batch_test['margins'],\n",
    "        x_shape_pl: batch_test['shapes'],\n",
    "        x_texture_pl: batch_test['textures'],\n",
    "        is_training_pl: False\n",
    "    }\n",
    "    # get the result\n",
    "    res_test = sess.run(fetches=fetches_test, feed_dict=feed_dict_test)\n",
    "    y_out = res_test[0]\n",
    "    ids_test.append(batch_test['ids'])\n",
    "    if num!=len(y_out):\n",
    "        # in case of the last batch, num will be less than batch_size\n",
    "        y_out = y_out[:num]\n",
    "    preds_test.append(y_out)\n",
    "# concatenate it all, to form one list/array\n",
    "ids_test = list(itertools.chain.from_iterable(ids_test))\n",
    "preds_test = np.concatenate(preds_test, axis=0)\n",
    "assert len(ids_test) == len(preds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame(preds_test, columns=data.le.classes_)\n",
    "ids_test_df = pd.DataFrame(ids_test, columns=[\"id\"])\n",
    "submission = pd.concat([ids_test_df, preds_df], axis=1)\n",
    "submission.to_csv('submission_mlp.csv', index=False)\n",
    "# below prints the submission, can be removed and replaced with code block below\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload submission\n",
    "\n",
    "1. Go to `https://www.kaggle.com/c/leaf-classification/`\n",
    "2. Make a submission\n",
    "3. Click or drop your submission here (writing a description is good practice)\n",
    "4. Submit\n",
    "\n",
    "Success! now you can view your score on the leaderboard, try and see if you can beat me! (Alexander Rosenberg Johansen: 0.06399)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "When doing these exercises nothing is sacred, you can change learning rate, try testing various learning rates, batch sizes, validation sizes, etc. And most importantly, the validation set is very small (only 1 sample per class), so try different seeds if evaluating the same model twice.\n",
    "\n",
    "Describe how each of below tasks effects training:\n",
    "\n",
    "1. Set DROPOUT to TRUE\n",
    "2. Include L2 regularization\n",
    "3. Try with L1 regularization\n",
    "4. Use only the image for training (with CNN)\n",
    "5. Comment in dropout from CNN layers\n",
    "6. Include the RNN part"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
