# TensorFlow Tutorial - used by Nvidia
Learn TensorFlow from scratch by examples and visualizations with interactive jupyter notebooks. Learn to compete in the [Kaggle leaf detection challenge](https://www.kaggle.com/c/leaf-classification)!

All exercises are designed to be run from a CPU on a laptop, but can be accelerated with GPU resources.

Lab 1-4 was used in the [Deep Learning using TensorFlow](http://www.eventbrite.com/e/deep-learning-using-tensorflow-tickets-27071720244#) in London by Nvidia and Persontyle

## Setup and Installation

Guides for downloading and installing TensorFlow on Linux, OSX and Windows using Docker can be found [here](https://github.com/alrojo/tensorflow-tutorial/tree/master/download-and-setup).

## Material

The material consists of 5 labs.

### [Lab1 - FFN](https://github.com/alrojo/tensorflow-tutorial/tree/master/lab1_FFN)

Logistic regression, feed forward neural network (FFN) on the (in)famous MNIST!

Optional reading material from [Michael Nielsen](http://neuralnetworksanddeeplearning.com/) chapters 1-4 (Do 3-5 of the optional exercises).

### [Lab2 - CNN](https://github.com/alrojo/tensorflow-tutorial/tree/master/lab2_CNN)

Convolutional Neural Network (CNN) and Spatial Transformer on images.

Optional reading material from [Michael Nielsen](http://neuralnetworksanddeeplearning.com/) chapter 6 (stop when reaching section called Other approaches to deep neural nets).

### [Lab3 - RNN](https://github.com/alrojo/tensorflow-tutorial/tree/master/lab3_RNN)

Recurrent Neural Network (RNN) on Translation using Encoder-Decoder model and Encoder-Decoder with attention.

Optional reading material from [Alex Graves](https://www.cs.toronto.edu/~graves/preprint.pdf) chapters 3.1, 3.2 and 4,

### [Lab4 - Kaggle](https://github.com/alrojo/tensorflow-tutorial/tree/master/lab4_Kaggle)

Compete in the kaggle competition [Leaf Classification](https://www.kaggle.com/c/leaf-classification) using FFN, CNN and RNN.

### [Lab5 - AE](https://github.com/alrojo/tensorflow-tutorial/tree/master/lab5_AE)

Unsupervised learning with autoencoder (AE) reconstructing the MNIST from only two latent variables.

Optional reading material from [deeplearningbook.org](http://www.deeplearningbook.org/contents/autoencoders.html) chapter 14.

## Credits

Labs 1, 2, 3 and 5 have been translated from Theano/Lasagne with minor modifications from the following repositories: [Nvidia Summer Camp](https://github.com/DeepLearningDTU/nvidia_deep_learning_summercamp_2016) and [02456 deep learning](https://github.com/DeepLearningDTU/02456-deep-learning). Original authors: [skaae](https://github.com/skaae), [casperkaae](https://github.com/casperkaae) and [larsmaaloee](https://github.com/larsmaaloee).

Thanks to professor [Ole Winther](http://cogsys.imm.dtu.dk/staff/winther/) for supervision and sponsoring the labs.
